# Pytorch_tutorial
## Object: learn Pytorch for DeepLearning
## Date: 2023.05.25 ~ 2023.

<br>

### 튜토리얼 사용 방법 (출처: https://tutorials.pytorch.kr/beginner/basics/intro.html)
다른 딥러닝 프레임워크에 익숙하다면, 0. 빠른 시작 을 보고 PyTorch의 API들을 빠르게 익히세요.  
딥러닝 프레임워크가 처음이라면, 단계별(step-by-step) 가이드의 첫번째인 1. 텐서(Tensor) 로 이동하세요.
<br>

0. 빠른 시작
1. 텐서(Tensor)
2. Dataset과 DataLoader
3. 변형(Transform)
4. 신경망 모델 구성하기
5. 자동 미분(Automatic Differentiation)
6. 최적화 단계(Optimization Loop)
7. 모델 저장하고 불러오고 사용하기

### 1. 텐서
- ndarray를 교육받을 때 말고는 배운 적이 없어서 긴장했는데, ones zeors rand 등 기본적인 특징은 공유하는 데이터 타입이어서 조금 친근해졌다. 자주 사용하기만 하면 문제는 해결해가며 할 수 있을 것 같다.
- tensor는 속성으로 모양, 자료형, 그리고 어느 장치에 저장되는지를 확인했는데 그전에도 어느 장치에 저장되는지 확인해본적이 없어서 특별한 속성인지, 그렇다면 어디에 쓰이는지 궁금했다.
    - 파이토치 모델 혹은 텐서가 올라가는 모델에 따라 CPU 혹은 GPU 연산을 하는지 확인하는 것 같다. 추후 진행에서 확인해봐야지
- colab에서 GPU 할당하기 위해서는 edit, 수정 탭에서 Notebook Settings인 노트설정에 들어가면 GPU를 할당할 수 있다. 아직 세부사항은 무얼 뜻하는지 몰라서 수정하지 않았다. 기본으로 주어지는 것이 가장 안전하다는 지론을 따라가기로 했다. device type이 cuda로 바뀌었다. 맞는건가?
- 표준 인덱싱과 슬라이싱은 리스트를 사용할 때와 같다.
- 텐서를 합치는 방식에는 cat과 stack이 있다.
    - cat은 가로로 연장
    - stack은 겹친다. 차원이 달라지는 느낌 그런데 dim 속성을 바꾸면 쌓이는 방향이 바뀌나보다. 이전에 stack을 배웠던것을 다시 확인해봐야할듯
- 산술 연산에서 곱하기는 mul을 활용, 행렬곱은 matmul을 활용한다. 약자는 *와 @를 활용한다. 다만 텐서에 바로 함수를 .뒤에 활용하는 방법도 있지만, torch.함수(첫인수, 두인수, out=연산결과인수)로 활용하기도 한다. 마지막 방법은 처음본다. 특히 out=을 활용하는 것이 과연 일반적으로 선언하는 방식보다 가독성에 좋은 방법인지 궁금하다.
- 바꿔치기 연산을 처음 본다. _를 함수 끝에 붙인다. 메모리를 절약하지만 기록을 바로 삭제하여 도함수 연산 중 문제가 발생할 수 있다며 권장하지 않는다고 한다. 후에 다시 나오기 전까지는 활용하지 않는 것이 좋겠다. 다만 언제 쓰는지 확인이 필요하다.
- numpy배열과 tensor는 메모리 공간을 공유하기 때문에 변경사항이 동시에 적용된다고 한다. 이게 뭔소리인가? 마치 dataframe을 copy하지 않고 바로 다른 이름을 부여해서 사용해서 쓰면 변경사항이 동시에 적용되던 것이 기억난다. 같은 내용인가?